{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12098bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------KNN USING TUNNED PARAMETERS-----------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, label_binarize\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score,\n",
    "                             f1_score, precision_score, recall_score, cohen_kappa_score,\n",
    "                             brier_score_loss)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------- LOAD & LABEL DATA -------------------\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "AttackFree= pd.read_csv('Attack_free new.csv')[0:355409]\n",
    "DoS= pd.read_csv('DoS_Attack_new.csv')[0:98486]\n",
    "Fuzzy= pd.read_csv('Fuzzy_Attack_New.csv')[0:88798]\n",
    "Impersonation= pd.read_csv('Impersonation_Attack_New.csv')[0:149320]\n",
    "\n",
    "for df in [AttackFree, DoS, Fuzzy, Impersonation]:\n",
    "    for col in df.columns[1:16]:\n",
    "        df[col] = label_encoder.fit_transform(df[col].astype(str))\n",
    "\n",
    "label1 = [1] * len(AttackFree)\n",
    "label2 = [2] * len(DoS)\n",
    "label3 = [3] * len(Fuzzy)\n",
    "label4 = [4] * len(Impersonation)\n",
    "\n",
    "Dataset = np.concatenate((AttackFree, DoS, Fuzzy, Impersonation))\n",
    "Labels = np.concatenate((label1, label2, label3, label4))\n",
    "\n",
    "# ------------------- TRAIN/TEST SPLIT -------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(Dataset, Labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# ------------------- SCALING -------------------\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# ------------------- OVERSAMPLING -------------------\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_bal, y_train_bal = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# ------------------- TRAIN TUNED KNN -------------------\n",
    "knn = KNeighborsClassifier(\n",
    "    n_neighbors=5,\n",
    "    weights='distance',\n",
    "    algorithm='auto',\n",
    "    leaf_size=20,\n",
    "    p=1\n",
    ")\n",
    "\n",
    "start_train = datetime.now()\n",
    "knn.fit(X_train_bal, y_train_bal)\n",
    "end_train = datetime.now()\n",
    "print(f\" Training Time: {end_train - start_train}\")\n",
    "\n",
    "# ------------------- TESTING -------------------\n",
    "start_test = datetime.now()\n",
    "y_pred = knn.predict(X_test)\n",
    "end_test = datetime.now()\n",
    "print(f\"Testing Time: {end_test - start_test}\")\n",
    "\n",
    "# ------------------- METRICS -------------------\n",
    "print(\"\\n Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=['AttackFree', 'DoS', 'Fuzzy', 'Impersonation']))\n",
    "\n",
    "# ------------------- CONFUSION MATRIX -------------------\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "labels = ['AttackFree', 'DoS', 'Fuzzy', 'Impersonation']\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.heatmap(pd.DataFrame(cm, index=labels, columns=labels), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title(\"Confusion Matrix - Tuned KNN\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ------------------- TPR / TNR -------------------\n",
    "TPR, TNR = [], []\n",
    "for i in range(len(cm)):\n",
    "    tp = cm[i, i]\n",
    "    fn = cm[i, :].sum() - tp\n",
    "    fp = cm[:, i].sum() - tp\n",
    "    tn = cm.sum() - (tp + fn + fp)\n",
    "    TPR.append(tp / (tp + fn) if (tp + fn) else 0)\n",
    "    TNR.append(tn / (tn + fp) if (tn + fp) else 0)\n",
    "\n",
    "print(\"True Positive Rate (TPR) and True Negative Rate (TNR) per class:\")\n",
    "for i, cls in enumerate(labels):\n",
    "    print(f\"{cls}:\\n TPR = {TPR[i]:.4f}, TNR = {TNR[i]:.4f}\")\n",
    "\n",
    "# ------------------- SUMMARY METRICS -------------------\n",
    "print(\"\\n Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\" Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\" Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\" F1 Score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\" Cohen Kappa Score:\", cohen_kappa_score(y_test, y_pred))\n",
    "\n",
    "# ------------------- INFERENCE LATENCY -------------------\n",
    "sample_input = X_test[:1000]\n",
    "start_inf = time.time()\n",
    "_ = knn.predict(sample_input)\n",
    "end_inf = time.time()\n",
    "latency_ms = (end_inf - start_inf) / len(sample_input) * 1000\n",
    "\n",
    "print(f\"\\nInference Time for 1000 samples: {end_inf - start_inf:.4f} sec\")\n",
    "print(f\"Average Latency per Sample: {latency_ms:.4f} ms\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
