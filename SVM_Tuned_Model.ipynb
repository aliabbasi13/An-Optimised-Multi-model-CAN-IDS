{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f14d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====TUNED SVM Model =====\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    precision_score, recall_score, f1_score, cohen_kappa_score,\n",
    "    hinge_loss\n",
    ")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------DATA LOADING---------\n",
    " \n",
    "AttackFree= pd.read_csv('Attack_free new.csv')[0:355409]\n",
    "DoS= pd.read_csv('DoS_Attack_new.csv')[0:98486]\n",
    "Fuzzy= pd.read_csv('Fuzzy_Attack_New.csv')[0:88798]\n",
    "Impersonation= pd.read_csv('Impersonation_Attack_New.csv')[0:149320]\n",
    "\n",
    "n1, n2, n3, n4 = len(AttackFree), len(DoS), len(Fuzzy), len(Impersonation)\n",
    "\n",
    "# ------------UNIFORM DATAFRAME---------------------------------------\n",
    "\n",
    "X_df = pd.concat([AttackFree, DoS, Fuzzy, Impersonation], axis=0, ignore_index=True)\n",
    "\n",
    "# -----------------PREPROCESSING---------------------------\n",
    "for col in X_df.columns:\n",
    "    \n",
    "    col_as_num = pd.to_numeric(X_df[col], errors='coerce')\n",
    "   \n",
    "    if col_as_num.isna().mean() > 0.5:\n",
    "        le = LabelEncoder()\n",
    "        X_df[col] = le.fit_transform(X_df[col].astype(str))\n",
    "    else:\n",
    "        X_df[col] = col_as_num.fillna(col_as_num.median())\n",
    "\n",
    "# -----------------------LABELLING ------------------------\n",
    "y = np.r_[\n",
    "    np.full(n1, 1, dtype=int),\n",
    "    np.full(n2, 2, dtype=int),\n",
    "    np.full(n3, 3, dtype=int),\n",
    "    np.full(n4, 4, dtype=int)\n",
    "]\n",
    "\n",
    "# ------CLASS WEIGHTS -------------------------------\n",
    "classes = np.unique(y)\n",
    "class_weights_array = compute_class_weight(class_weight='balanced', classes=classes, y=y)\n",
    "class_weights_dict = dict(zip(classes, class_weights_array))\n",
    "print(\"Class Weights:\", class_weights_dict)\n",
    "\n",
    "# 5) Stratify TRAIN/TEST SPLIT -----------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_df.values, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ----------- SVM Model USING SVC with tuned parameters------\n",
    "clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(\n",
    "        kernel='rbf',\n",
    "        C=100,\n",
    "        gamma='scale',\n",
    "        class_weight=class_weights_dict,\n",
    "        probability=False,\n",
    "        random_state=42,\n",
    "        cache_size=1000,\n",
    "        tol=1e-3\n",
    "    ))\n",
    "])\n",
    "\n",
    "# ---------TRAINING------------\n",
    "t0 = datetime.now()\n",
    "clf.fit(X_train, y_train)\n",
    "t1 = datetime.now()\n",
    "print(' Training Duration:', t1 - t0)\n",
    "\n",
    "# ---------- TESTING---------- \n",
    "t2 = datetime.now()\n",
    "y_pred = clf.predict(X_test)\n",
    "t3 = datetime.now()\n",
    "print(' Testing Duration:', t3 - t2)\n",
    "\n",
    "# === INFERENCE LATENCY ------------\n",
    "sample_n = min(1000, len(X_test))\n",
    "sample_input = X_test[:sample_n]\n",
    "ts = time.time()\n",
    "_ = clf.predict(sample_input)\n",
    "te = time.time()\n",
    "print(f\"\\n Inference Time for {sample_n} samples: {te - ts:.4f} s\")\n",
    "print(f\" Avg Latency per Sample: {(te - ts)/sample_n * 1000:.4f} ms\")\n",
    "\n",
    "# ---------EVALUATION METRICS\n",
    "print(\"\\n Classification Report (Tuned SVM):\")\n",
    "print(classification_report(y_test, y_pred, target_names=['AttackFree', 'DoS', 'Fuzzy', 'Impersonation']))\n",
    "\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\" Precision: {precision_score(y_test, y_pred, average='micro'):.4f}\")\n",
    "print(f\" Recall:    {recall_score(y_test, y_pred, average='micro'):.4f}\")\n",
    "print(f\" F1 Score:  {f1_score(y_test, y_pred, average='micro'):.4f}\")\n",
    "print(f\" Cohen Kappa: {cohen_kappa_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "#----------- CONFUSION MATRIX + TPR/TNR -------------------\n",
    "labels = ['AttackFree', 'DoS', 'Fuzzy', 'Impersonation']\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[1,2,3,4])\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.heatmap(pd.DataFrame(cm, index=labels, columns=labels), annot=True, cmap='Blues', fmt='d')\n",
    "plt.title(\"Confusion Matrix - Tuned SVM (RBF, C=100, gamma='scale')\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "TPR, TNR = [], []\n",
    "for i in range(len(labels)):\n",
    "    tp = cm[i, i]\n",
    "    fn = cm[i, :].sum() - tp\n",
    "    fp = cm[:, i].sum() - tp\n",
    "    tn = cm.sum() - (tp + fn + fp)\n",
    "    TPR.append(tp / (tp + fn) if (tp + fn) else 0)\n",
    "    TNR.append(tn / (tn + fp) if (tn + fp) else 0)\n",
    "\n",
    "print(\"\\n TPR (Recall) and TNR (Specificity) per class:\")\n",
    "for i, cls in enumerate(labels):\n",
    "    print(f\"{cls}:   TPR = {TPR[i]:.4f}    TNR = {TNR[i]:.4f}\")\n",
    "\n",
    "# ----- Hinge loss using decision_function\n",
    "\n",
    "scores = clf.named_steps['svm'].decision_function(clf.named_steps['scaler'].transform(X_test))\n",
    "print(f\"\\n Hinge Loss: {hinge_loss(y_test, scores, labels=[1,2,3,4]):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
