{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74691da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------DNN TUNNING with Focal Loss and Class Weights--------------------------\n",
    "\n",
    "!pip install tensorflow\n",
    "\n",
    "# ----------------------- IMPORTS -----------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------- FOCAL LOSS -------------------\n",
    "def sparse_categorical_focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        y_true_one_hot = tf.one_hot(y_true, depth=y_pred.shape[-1])\n",
    "        cross_entropy = K.categorical_crossentropy(y_true_one_hot, y_pred)\n",
    "        pt = tf.reduce_sum(y_true_one_hot * y_pred, axis=-1)\n",
    "        focal_loss = alpha * tf.pow(1. - pt, gamma) * cross_entropy\n",
    "        return focal_loss\n",
    "    return loss_fn\n",
    "\n",
    "# ------------------- DATA LOADING -------------------\n",
    "attack_free = pd.read_csv(\"Attack_free new.csv\")[0:2369397]\n",
    "dos = pd.read_csv(\"DoS_Attack_new.csv\")[0:656578]\n",
    "fuzzy = pd.read_csv(\"Fuzzy_Attack_New.csv\")[0:591989]\n",
    "impersonation = pd.read_csv(\"Impersonation_Attack_New.csv\")[0:995471]\n",
    "\n",
    "# ------------------- Pre Processing -------------------\n",
    "attack_free['label'] = 0\n",
    "dos['label'] = 1\n",
    "fuzzy['label'] = 2\n",
    "impersonation['label'] = 3\n",
    "\n",
    "df = pd.concat([attack_free, dos, fuzzy, impersonation], ignore_index=True)\n",
    "df = df.drop(columns=[col for col in df.columns if 'Unnamed' in col])\n",
    "\n",
    "for col in df.columns[:-1]:\n",
    "    df[col] = df[col].apply(lambda x: int(str(x), 16) if isinstance(x, str) and all(c in '0123456789abcdefABCDEF' for c in str(x)) else x)\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df.drop(columns='label').values\n",
    "y = df['label'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state=42)\n",
    "\n",
    "# ------------------- CLASS WEIGHTS -------------------\n",
    "cw = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = dict(enumerate(cw))\n",
    "\n",
    "# ------------------- MODEL BUILDING -------------------\n",
    "model = Sequential([\n",
    "    Input(shape=(X.shape[1],)),\n",
    "    Dense(448, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(32, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(96, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(48, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss=sparse_categorical_focal_loss(gamma=2.0, alpha=0.25),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ------------------- TRAINING -------------------\n",
    "start_train = time.time()\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "end_train = time.time()\n",
    "print(f\"\\n Total Training Time: {end_train - start_train:.2f} seconds\")\n",
    "\n",
    "history_dnn = history\n",
    "\n",
    "\n",
    "# === Plot Training & Validation Loss ===\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss', linestyle='-', color='blue')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', linestyle='--', color='orange')\n",
    "plt.title('Training vs Validation Loss (DNN)', fontsize=14, weight='bold')\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', linewidth=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"dnn_training_validation_loss.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ------------------- EVALUATION -------------------\n",
    "start_test = time.time()\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest Accuracy: {acc:.4f}\")\n",
    "print(f\" Loss: {loss:.4f}\")\n",
    "end_test = time.time()\n",
    "print(f\" Total Testing Time: {end_test - start_test:.2f} seconds\")\n",
    "\n",
    "\n",
    "#-------------------- PREDICTIONS AND REPORTS -------------------\n",
    "y_pred = model.predict(X_test).argmax(axis=1)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['AttackFree', 'DoS', 'Fuzzy', 'Impersonation'],\n",
    "            yticklabels=['AttackFree', 'DoS', 'Fuzzy', 'Impersonation'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix Tuned DNN\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix_final.png\")\n",
    "\n",
    "# ------------------- SAVE MODEL -------------------\n",
    "model.save(\"final_CAN_IDS_model.h5\")\n",
    "\n",
    "\n",
    "\n",
    "# === Latency Measurement ===\n",
    "sample_input = X_test[:1000]  # Use 1000 samples\n",
    "start = time.time()\n",
    "_ = model.predict(sample_input, verbose=0)\n",
    "end = time.time()\n",
    "\n",
    "latency = (end - start) / len(sample_input)\n",
    "print(f\"\\nInference Time for 1000 samples: {end - start:.4f} seconds\")\n",
    "print(f\"Average Latency per Sample: {latency * 1000:.4f} ms\")\n",
    "\n",
    "\n",
    "\n",
    "# === TPR & TNR Calculation for DNN ===\n",
    "\n",
    "TPR = []  # True Positive Rate (Recall)\n",
    "TNR = []  # True Negative Rate (Specificity)\n",
    "\n",
    "for i in range(len(cm)):\n",
    "    tp = cm[i, i]\n",
    "    fn = cm[i, :].sum() - tp\n",
    "    fp = cm[:, i].sum() - tp\n",
    "    tn = cm.sum() - (tp + fn + fp)\n",
    "\n",
    "    tpr = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "    tnr = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "\n",
    "    TPR.append(tpr)\n",
    "    TNR.append(tnr)\n",
    "\n",
    "# === Print TPR and TNR Table ===\n",
    "print(\"\\n True Positive Rate (TPR) and True Negative Rate (TNR) for each class:\")\n",
    "for i, cls in enumerate(['AttackFree', 'DoS', 'Fuzzy', 'Impersonation']):\n",
    "    print(f\"{cls}:\")\n",
    "    print(f\"   TPR (Recall): {TPR[i]:.4f}\")\n",
    "    print(f\"   TNR (Specificity): {TNR[i]:.4f}\")\n",
    "\n",
    "\n",
    "# === TPR & FPR Calculation for DNN ===\n",
    "TPR = []  \n",
    "FPR = []  \n",
    "\n",
    "for i in range(len(cm)):\n",
    "    tp = cm[i, i]\n",
    "    fn = cm[i, :].sum() - tp\n",
    "    fp = cm[:, i].sum() - tp\n",
    "    tn = cm.sum() - (tp + fn + fp)\n",
    "\n",
    "    tpr = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "    fpr = fp / (fp + tn) if (fp + tn) != 0 else 0\n",
    "\n",
    "    TPR.append(tpr)\n",
    "    FPR.append(fpr)\n",
    "\n",
    "# === Print TPR and FPR Table ===\n",
    "print(\"\\ True Positive Rate (TPR) and False Positive Rate (FPR) for each class:\")\n",
    "for i, cls in enumerate(['AttackFree', 'DoS', 'Fuzzy', 'Impersonation']):\n",
    "    print(f\"{cls}:\")\n",
    "    print(f\"   TPR (Recall): {TPR[i]:.4f}\")\n",
    "    print(f\"   FPR (Fall-out): {FPR[i]:.4f}\")\n",
    "\n",
    "\n",
    "# === Average TPR and FPR ===\n",
    "avg_tpr = np.mean(TPR)\n",
    "avg_fpr = np.mean(FPR)\n",
    "# === Overall accuracy\n",
    "overall_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# === Print Summary ===\n",
    "print(\"\\n Average Metrics Across All Datasets:\")\n",
    "print(f\" Average TPR (Recall): {avg_tpr:.4f}\")\n",
    "print(f\" Average FPR (Fall-out): {avg_fpr:.4f}\")\n",
    "print(f\" Overall Accuracy: {overall_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
