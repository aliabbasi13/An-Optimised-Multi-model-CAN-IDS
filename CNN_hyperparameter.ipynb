{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc25b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------CNN TUNNING TRIAL-------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras_tuner as kt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Bidirectional, LSTM\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Multiply, Permute, Lambda\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# ---------------------- LOAD & PREPROCESS DATA ----------------------\n",
    "attack_free = pd.read_csv(\"Attack_free new.csv\")[0:2369397]\n",
    "dos = pd.read_csv(\"DoS_Attack_new.csv\")[0:656578]\n",
    "fuzzy = pd.read_csv(\"Fuzzy_Attack_New.csv\")[0:591989]\n",
    "impersonation = pd.read_csv(\"Impersonation_Attack_New.csv\")[0:995471]\n",
    "\n",
    "for df, label in zip([attack_free, dos, fuzzy, impersonation], [0, 1, 2, 3]):\n",
    "    df['label'] = label\n",
    "\n",
    "df = pd.concat([attack_free, dos, fuzzy, impersonation], ignore_index=True)\n",
    "df = df.drop(columns=[col for col in df.columns if 'Unnamed' in col])\n",
    "\n",
    "for col in df.columns[:-1]:\n",
    "    df[col] = df[col].apply(lambda x: int(str(x), 16) if isinstance(x, str) and all(c in '0123456789abcdefABCDEF' for c in str(x)) else x)\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df.drop(columns='label').values\n",
    "y = df['label'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state=42)\n",
    "\n",
    "y_train_cat = to_categorical(y_train, num_classes=4)\n",
    "y_test_cat = to_categorical(y_test, num_classes=4)\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# ---------------------- CUSTOM ATTENTION ----------------------\n",
    "def attention_layer(inputs):\n",
    "    attention = Dense(inputs.shape[1], activation='softmax')(inputs)\n",
    "    attention = Permute((2, 1))(attention)\n",
    "    attention = Lambda(lambda x: K.mean(x, axis=1))(attention)\n",
    "    attention = Dense(inputs.shape[-1], activation='sigmoid')(attention)\n",
    "    return Multiply()([inputs, attention])\n",
    "\n",
    "# ---------------------- HYPERMODEL ----------------------\n",
    "def build_cnn_bilstm_model(hp):\n",
    "    input_layer = Input(shape=(X.shape[1], 1))\n",
    "\n",
    "    x = Conv1D(\n",
    "        filters=hp.Int('conv_filters', 32, 128, step=32),\n",
    "        kernel_size=hp.Choice('kernel_size', [3, 5]),\n",
    "        activation='relu'\n",
    "    )(input_layer)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    x = Bidirectional(LSTM(\n",
    "        hp.Int('lstm_units', 32, 128, step=32),\n",
    "        return_sequences=True\n",
    "    ))(x)\n",
    "\n",
    "    x = attention_layer(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(hp.Int('dense_1', 64, 256, step=64), activation='relu')(x)\n",
    "    x = Dropout(hp.Float('dropout_1', 0.2, 0.5, step=0.1))(x)\n",
    "\n",
    "    x = Dense(hp.Int('dense_2', 32, 128, step=32), activation='relu')(x)\n",
    "    x = Dropout(hp.Float('dropout_2', 0.2, 0.5, step=0.1))(x)\n",
    "\n",
    "    output = Dense(4, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp.Choice('lr', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ---------------------- HYPERBAND TUNING ----------------------\n",
    "tuner = kt.Hyperband(\n",
    "    build_cnn_bilstm_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=100,\n",
    "    factor=3,\n",
    "    directory='cnn_bilstm_tuning',\n",
    "    project_name='CAN_IDS_CNN_BiLSTM'\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "tuner.search(\n",
    "    X_train, y_train_cat,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ---------------------- TRAIN BEST MODEL ----------------------\n",
    "best_hps = tuner.get_best_hyperparameters(1)[0]\n",
    "print(\"\\nðŸ”§ Best Hyperparameters Found:\")\n",
    "for param in best_hps.values:\n",
    "    print(f\"{param}: {best_hps.get(param)}\")\n",
    "\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "history = best_model.fit(\n",
    "    X_train, y_train_cat,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "loss, acc = best_model.evaluate(X_test, y_test_cat)\n",
    "print(f\"\\n Tuned CNN+BiLSTM Accuracy: {acc:.4f}\")\n",
    "best_model.save(\"tuned_CNN_BiLSTM_model.h5\")\n",
    "\n",
    "\n",
    "#---------------------- AUROC CALCULATION ----------------------\n",
    "\n",
    "\n",
    "\n",
    "# Binarize the test labels\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2, 3])\n",
    "\n",
    "# Predict class probabilities\n",
    "y_score = model.predict(X_test)\n",
    "\n",
    "# Compute AUROC for each class\n",
    "auroc_per_class = roc_auc_score(y_test_bin, y_score, average=None)\n",
    "\n",
    "# Print AUROC for each class\n",
    "class_names = ['AttackFree', 'DoS', 'Fuzzy', 'Impersonation']\n",
    "print(\"\\n AUROC Score per Class:\")\n",
    "for i, score in enumerate(auroc_per_class):\n",
    "    print(f\"{class_names[i]}: AUROC = {score:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
